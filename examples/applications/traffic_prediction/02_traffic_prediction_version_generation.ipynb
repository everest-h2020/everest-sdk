{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceaa50bc-e192-4c7f-afa1-71cdac035191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after kernel restart, always execute this line\n",
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.insert(0, 'path/to/everest-basecamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c919d59-533a-4879-9b62-e9ee99d2929c",
   "metadata": {},
   "source": [
    "Basceamp inference flow / DOSA part\n",
    "----------------------------------------\n",
    "This example assumes the training & export as shown e.g. in notebook 01. \n",
    "\n",
    "### ML-developer part\n",
    "This time, a pytorch model is used as input. Also, some data are used to calibrate the weights for the quantized datatype. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adb50afb-8bdb-4741-978d-9b2473dd0d5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ebc import basecamp\n",
    "\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "emli = basecamp.ml_inference\n",
    "emli.set_constraints(app_name=\"EVEREST traffic prediction v1\",\n",
    "                     onnx_input_name='x',\n",
    "                     input_shape=[batch_size, 17],\n",
    "                     input_size_t=8,  # in bits \n",
    "                     quantization='int8', \n",
    "                     batch_size=batch_size,\n",
    "                     target_throughput=5000,  # batch_size inferences per second\n",
    "                     arch_gen_strategy='throughput'\n",
    "                     )\n",
    "# set outpupt path\n",
    "emli.set_output_path('build_dirs/etp_v1')\n",
    "\n",
    "# set pytorch model as input\n",
    "emli.set_model_path(\"torchscript\", './etp_01.pt')\n",
    "\n",
    "# we can pass calibration data\n",
    "emli.set_calibration_data_path('./traffic_data_2023-04-26.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df99dfcb-724d-4913-947b-520a464d6efc",
   "metadata": {},
   "source": [
    "### Performance engineer part\n",
    "(just as example)\n",
    "As described in the user story, the performance engineer could modify global or high-level configuration of DOSA to accomodate applicaiton specific architectural trade-offs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad3b53be-a1ac-4a5d-9993-c468cd6d1e13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emli.dosa_config['build']['comm_message_interleaving'] = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab08668d-27f7-4fdf-814c-2fd9220413c4",
   "metadata": {},
   "source": [
    "### DOSA compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6524d114-9f7e-49a0-89c2-dd9a2d084248",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ngl/gitrepos/EVEREST/everest-basecamp/venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DOSA:config:INFO] Allowing a degredation of the throughput of 0.1 from the targeted throughput.\n",
      "[DOSA:build:INFO] Not deleting existing content in output dir.\n",
      "DOSA: Building OSGs, communication and device libraries...\n",
      "\t...done.\n",
      "\n",
      "DOSA: Parsing constraints...\n",
      "\t...done.\n",
      "\n",
      "DOSA: Importing TorchScript...\n",
      "\t...done.\n",
      "DOSA: Starting quantization translation...\n",
      "\t...done.\n",
      "DOSA: Starting quantization calibration (1000 steps) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ngl/gitrepos/EVEREST/everest-basecamp/venv/lib64/python3.8/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t...done.\n",
      "DOSA: Building quantized AST...\n",
      "Previous exported models deleted!\n",
      "step brevitas export\n",
      "step tidy up\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ngl/gitrepos/EVEREST/everest-basecamp/venv/lib/python3.8/site-packages/qonnx/core/modelwrapper.py:93: UserWarning: Some old-style domain attributes were automatically converted to new-style,\n",
      "                i.e. domain=finn to domain=qonnx.custom_op.<general|fpgadataflow|...>\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step streamline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ngl/gitrepos/EVEREST/everest-basecamp/venv/lib/python3.8/site-packages/qonnx/transformation/infer_data_layouts.py:124: UserWarning: Assuming 2D input is NC\n",
      "  warnings.warn(\"Assuming 2D input is NC\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step finn to DOSA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[10:53:39] /home/ngl/gitrepos/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[10:53:39] /home/ngl/gitrepos/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[10:53:39] /home/ngl/gitrepos/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[10:53:39] /home/ngl/gitrepos/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[10:53:39] /home/ngl/gitrepos/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[10:53:39] /home/ngl/gitrepos/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[10:53:39] /home/ngl/gitrepos/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[10:53:39] /home/ngl/gitrepos/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[10:53:39] /home/ngl/gitrepos/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[10:53:39] /home/ngl/gitrepos/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[10:53:39] /home/ngl/gitrepos/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[10:53:39] /home/ngl/gitrepos/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[10:53:39] /home/ngl/gitrepos/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[10:53:39] /home/ngl/gitrepos/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[10:53:39] /home/ngl/gitrepos/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[10:53:39] /home/ngl/gitrepos/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[10:53:39] /home/ngl/gitrepos/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[10:53:39] /home/ngl/gitrepos/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[10:53:39] /home/ngl/gitrepos/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[10:53:39] /home/ngl/gitrepos/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[10:53:39] /home/ngl/gitrepos/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[10:53:39] /home/ngl/gitrepos/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[10:53:39] /home/ngl/gitrepos/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[10:53:39] /home/ngl/gitrepos/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[10:53:39] /home/ngl/gitrepos/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[10:53:39] /home/ngl/gitrepos/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n",
      "[10:53:39] /home/ngl/gitrepos/tvm/src/arith/int_set.cc:521: Warning: cannot evaluate set type tir.Call\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t...done.\n",
      "\n",
      "DOSA: Executing TVM optimization passes...\n",
      "\t...done.\n",
      "\n",
      "DOSA: Generating high-level architecture...\n",
      "[DOSA:OICALC:INFO] overwriting dtypes of function (input) with DosaDtype.int8 (orig: float32).\n",
      "[DOSA:OICALC:INFO] overwriting dtypes of function FN_0001 with DosaDtype.int8 (orig: float32).\n",
      "[DOSA:OICALC:INFO] overwriting dtypes of function FN_0002 with DosaDtype.int8 (orig: float32).\n",
      "[DOSA:OICALC:INFO] overwriting dtypes of function FN_0003 with DosaDtype.int8 (orig: float32).\n",
      "#[version = \"0.0.5\"]\n",
      "def @main(%global_in: Tensor[(1, 17), float32] /* ty=Tensor[(1, 17), float32] */) -> Tensor[(1, 4), float32] {\n",
      "  %4 = fn (%p02: Tensor[(1, 17), float32] /* ty=Tensor[(1, 17), float32] */, %p12: Tensor[(16, 17), float32] /* ty=Tensor[(16, 17), float32] */, %p21: Tensor[(16, 255), float32] /* ty=Tensor[(16, 255), float32] */, %p31: Tensor[(16, 255), float32] /* ty=Tensor[(16, 255), float32] */, Primitive=1) -> Tensor[(1, 16), float32] {\n",
      "    %2 = nn.dense(%p02, %p12, units=None, out_dtype=\"float32\") /* ty=Tensor[(1, 16), float32] */;\n",
      "    %3 = nn.multi_threshold(%2, %p21, out_dtype=\"INT8\", out_bias=-128f) /* ty=Tensor[(1, 16), float32] */;\n",
      "    nn.multi_threshold(%3, %p31, out_dtype=\"UINT8\", out_bias=0f) /* ty=Tensor[(1, 16), float32] */\n",
      "  } /* ty=fn (Tensor[(1, 17), float32], Tensor[(16, 17), float32], Tensor[(16, 255), float32], Tensor[(16, 255), float32]) -> Tensor[(1, 16), float32] */;\n",
      "  %5 = %4(%global_in, meta[relay.Constant][0] /* ty=Tensor[(16, 17), float32] */, meta[relay.Constant][1] /* ty=Tensor[(16, 255), float32] */, meta[relay.Constant][2] /* ty=Tensor[(16, 255), float32] */) /* ty=Tensor[(1, 16), float32] */;\n",
      "  %6 = fn (%p01: Tensor[(1, 16), float32] /* ty=Tensor[(1, 16), float32] */, %p11: Tensor[(8, 16), float32] /* ty=Tensor[(8, 16), float32] */, %p2: Tensor[(8, 255), float32] /* ty=Tensor[(8, 255), float32] */, %p3: Tensor[(8, 255), float32] /* ty=Tensor[(8, 255), float32] */, Primitive=1) -> Tensor[(1, 8), float32] {\n",
      "    %0 = nn.dense(%p01, %p11, units=None, out_dtype=\"float32\") /* ty=Tensor[(1, 8), float32] */;\n",
      "    %1 = nn.multi_threshold(%0, %p2, out_dtype=\"INT8\", out_bias=-128f) /* ty=Tensor[(1, 8), float32] */;\n",
      "    nn.multi_threshold(%1, %p3, out_dtype=\"UINT8\", out_bias=0f) /* ty=Tensor[(1, 8), float32] */\n",
      "  } /* ty=fn (Tensor[(1, 16), float32], Tensor[(8, 16), float32], Tensor[(8, 255), float32], Tensor[(8, 255), float32]) -> Tensor[(1, 8), float32] */;\n",
      "  %7 = %6(%5, meta[relay.Constant][3] /* ty=Tensor[(8, 16), float32] */, meta[relay.Constant][4] /* ty=Tensor[(8, 255), float32] */, meta[relay.Constant][5] /* ty=Tensor[(8, 255), float32] */) /* ty=Tensor[(1, 8), float32] */;\n",
      "  %8 = fn (%p0: Tensor[(1, 8), float32] /* ty=Tensor[(1, 8), float32] */, %p1: Tensor[(4, 8), float32] /* ty=Tensor[(4, 8), float32] */, Primitive=1) -> Tensor[(1, 4), float32] {\n",
      "    nn.dense(%p0, %p1, units=None, out_dtype=\"float32\") /* ty=Tensor[(1, 4), float32] */\n",
      "  } /* ty=fn (Tensor[(1, 8), float32], Tensor[(4, 8), float32]) -> Tensor[(1, 4), float32] */;\n",
      "  %8(%7, meta[relay.Constant][6] /* ty=Tensor[(4, 8), float32] */) /* ty=Tensor[(1, 4), float32] */\n",
      "}\n",
      "\n",
      "/* For debugging purposes the metadata section has been omitted.\n",
      " * If you would like to see the full metadata section you can set the \n",
      " * option to `True` when invoking `astext`. \n",
      " */\n",
      "[DOSA:MergeOps:INFO] Merged multi_threshold ArchOp(nn.multi_threshold) into ArchOp(nn.multi_threshold) successfully (parent: fn_0001).\n",
      "[DOSA:MergeOps:INFO] Merged multi_threshold ArchOp(nn.multi_threshold) into ArchOp(nn.multi_threshold) successfully (parent: fn_0002).\n",
      "[DOSA:archVerify:INFO] Draft ArchDraft(EVEREST traffic prediction v1, initial_annotated, OptimizationStrategies.THROUGHPUT) fulfills throughput requirement.\n",
      "\n",
      "[DOSA:archGen:INFO] Attempt to legalize draft with the following parameter set: {'consider_switching_first': True, 'contract_look_ahead': 0, 'relax_utilization_check': False}\n",
      "[DOSA:archGen:INFO] Setting ImplType of Brick 0 to STREAM, since there are no Engine implementations available.\n",
      "[DOSA:archGen:INFO] Setting ImplType of Brick 1 to STREAM, since there are no Engine implementations available.\n",
      "[DOSA:archGen:INFO] Setting ImplType of Brick 2 to STREAM, since there are no Engine implementations available.\n",
      "[DOSA:archGen:INFO] Selecting contract (BrickContr(fn(dense, multi_threshold) on cF_FMKU60_Themisto-Role_1 using hls4ml OSG/BrickImplTypes.STREAM: 155441.13/s, 1.95c%, 1.03m%, switching 0.21%c, 0.01%m)) for brick 0.\n",
      "[DOSA:archGen:INFO] Selecting contract (BrickContr(fn(dense, multi_threshold) on cF_FMKU60_Themisto-Role_1 using hls4ml OSG/BrickImplTypes.STREAM: 165156.20/s, 0.97c%, 0.51m%, switching 0.10%c, 0.01%m)) for brick 1.\n",
      "[DOSA:archGen:INFO] Selecting contract (BrickContr(fn(dense) on cF_FMKU60_Themisto-Role_1 using hls4ml OSG/BrickImplTypes.STREAM: 165156.20/s, 0.00c%, 0.00m%, switching 0.00%c, 0.00%m)) for brick 2.\n",
      "\n",
      "[DOSA:archGen:INFO] Attempt to legalize draft with the following parameter set: {'consider_switching_first': True, 'contract_look_ahead': 1, 'relax_utilization_check': False}\n",
      "[DOSA:archGen:INFO] Setting ImplType of Brick 0 to STREAM, since there are no Engine implementations available.\n",
      "[DOSA:archGen:INFO] Setting ImplType of Brick 1 to STREAM, since there are no Engine implementations available.\n",
      "[DOSA:archGen:INFO] Setting ImplType of Brick 2 to STREAM, since there are no Engine implementations available.\n",
      "[DOSA:archGen:INFO] Assuming hls4ml OSG as OSG for next brick(s)...\n",
      "[DOSA:archGen:INFO] Selecting contract (BrickContr(fn(dense, multi_threshold) on cF_FMKU60_Themisto-Role_1 using hls4ml OSG/BrickImplTypes.STREAM: 310882.26/s, 1.99c%, 1.07m%, switching 0.21%c, 0.01%m)) for brick 0.\n",
      "[DOSA:archGen:INFO] Assuming hls4ml OSG as OSG for next brick(s)...\n",
      "[DOSA:archGen:INFO] Selecting contract (BrickContr(fn(dense, multi_threshold) on cF_FMKU60_Themisto-Role_1 using hls4ml OSG/BrickImplTypes.STREAM: 330312.40/s, 0.99c%, 0.53m%, switching 0.10%c, 0.01%m)) for brick 1.\n",
      "[DOSA:archGen:INFO] Assuming hls4ml OSG as OSG for next brick(s)...\n",
      "[DOSA:archGen:INFO] Selecting contract (BrickContr(fn(dense) on cF_FMKU60_Themisto-Role_1 using hls4ml OSG/BrickImplTypes.STREAM: 660624.80/s, 0.01c%, 0.01m%, switching 0.00%c, 0.00%m)) for brick 2.\n",
      "\n",
      "[DOSA:archGen:INFO] Attempt to legalize draft with the following parameter set: {'consider_switching_first': True, 'contract_look_ahead': 2, 'relax_utilization_check': True}\n",
      "[DOSA:archGen:INFO] Setting ImplType of Brick 0 to STREAM, since there are no Engine implementations available.\n",
      "[DOSA:archGen:INFO] Setting ImplType of Brick 1 to STREAM, since there are no Engine implementations available.\n",
      "[DOSA:archGen:INFO] Setting ImplType of Brick 2 to STREAM, since there are no Engine implementations available.\n",
      "[DOSA:archGen:INFO] Assuming hls4ml OSG as OSG for next brick(s)...\n",
      "[DOSA:archGen:INFO] Selecting contract (BrickContr(fn(dense, multi_threshold) on cF_FMKU60_Themisto-Role_1 using hls4ml OSG/BrickImplTypes.STREAM: 310882.26/s, 1.99c%, 1.07m%, switching 0.21%c, 0.01%m)) for brick 0.\n",
      "[DOSA:archGen:INFO] Assuming hls4ml OSG as OSG for next brick(s)...\n",
      "[DOSA:archGen:INFO] Selecting contract (BrickContr(fn(dense, multi_threshold) on cF_FMKU60_Themisto-Role_1 using hls4ml OSG/BrickImplTypes.STREAM: 330312.40/s, 0.99c%, 0.53m%, switching 0.10%c, 0.01%m)) for brick 1.\n",
      "[DOSA:archGen:INFO] Assuming hls4ml OSG as OSG for next brick(s)...\n",
      "[DOSA:archGen:INFO] Selecting contract (BrickContr(fn(dense) on cF_FMKU60_Themisto-Role_1 using hls4ml OSG/BrickImplTypes.STREAM: 660624.80/s, 0.01c%, 0.01m%, switching 0.00%c, 0.00%m)) for brick 2.\n",
      "\n",
      "[DOSA:archGen:INFO] Node counts of all legal drafts: [1, 1, 1]\n",
      "[DOSA:archGen:INFO] Brick counts of all legal drafts: [3, 3, 3]\n",
      "[DOSA:archGen:INFO] Predicted iterations/s of all legal drafts: [155441.130413957, 310882.260827914, 310882.260827914]\n",
      "[DOSA:archGen:INFO] choosing draft 1, due to highest iteration/s prediction.\n",
      "\t...done.\n",
      "\n",
      "DOSA: Found best and valid draft, generating architecture and software in /home/ngl/gitrepos/EVEREST/traffic_prediction/build_dirs/etp_v1...\n",
      "\n",
      "gcc -c -D_XOPEN_SOURCE=700 -pedantic -Wall  -pthread --std=c++11 -g -fPIC -DMEASURE_PROTOCOL_WAIT -DPROGRESS_PRINT -lstdc++ -I./LIB/ -L./LIB/ dosa_infer.cpp -o dosa_infer.o\n",
      "gcc -c -D_XOPEN_SOURCE=700 -pedantic -Wall  -pthread --std=c++11 -g -fPIC -DMEASURE_PROTOCOL_WAIT -DPROGRESS_PRINT -lstdc++ -I./LIB/ -L./LIB/ LIB//ZRLMPI.cpp -o LIB//ZRLMPI.o\n",
      "gcc -c -D_XOPEN_SOURCE=700 -pedantic -Wall  -pthread --std=c++11 -g -fPIC -DMEASURE_PROTOCOL_WAIT -DPROGRESS_PRINT -lstdc++ -I./LIB/ -L./LIB/ LIB//zrlmpi_common.cpp -o LIB//zrlmpi_common.o\n",
      "gcc -o dosa_infer_pass.so  dosa_infer.o ./LIB//ZRLMPI.o ./LIB//zrlmpi_common.o -lstdc++ -I./LIB/ -L./LIB/ -shared\n",
      "[DOSA:DefaultCpuBuild:WARNING] Nothing to do for write_build_scripts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dosa_infer.cpp: In function ‘int infer_batch(char*, uint32_t, char*, uint32_t)’:\n",
      "dosa_infer.cpp:250:8: warning: variable ‘last_instruction_was_recv’ set but not used [-Wunused-but-set-variable]\n",
      "   bool last_instruction_was_recv = true;\n",
      "        ^~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "LIB//ZRLMPI.cpp: In function ‘int receiveHeader(long unsigned int, uint8_t, uint8_t, uint32_t, int, uint8_t*, bool, uint32_t)’:\n",
      "LIB//ZRLMPI.cpp:345:40: warning: comparison of integer expressions of different signedness: ‘uint32_t’ {aka ‘unsigned int’} and ‘int’ [-Wsign-compare]\n",
      "     if(!copyToCache && header.dst_rank != own_rank)\n",
      "                        ~~~~~~~~~~~~~~~~^~~~~~~~~~~\n",
      "LIB//ZRLMPI.cpp:118:12: warning: variable ‘expected_packet_cnt’ set but not used [-Wunused-but-set-variable]\n",
      "   uint32_t expected_packet_cnt = 0;\n",
      "            ^~~~~~~~~~~~~~~~~~~\n",
      "LIB//ZRLMPI.cpp: In function ‘void send_internal(int*, int, uint8_t, int, int, uint8_t)’:\n",
      "LIB//ZRLMPI.cpp:535:95: warning: ISO C++ forbids variable length array ‘buffer’ [-Wvla]\n",
      "     uint8_t buffer[(max_udp_payload_bytes+400)*typewidth*sizeof(uint32_t) + MPIF_HEADER_LENGTH];\n",
      "                                                                                               ^\n",
      "LIB//ZRLMPI.cpp:595:34: warning: comparison of integer expressions of different signedness: ‘int’ and ‘uint32_t’ {aka ‘unsigned int’} [-Wsign-compare]\n",
      "         if(count_of_this_message > max_udp_payload_bytes)\n",
      "            ~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~\n",
      "LIB//ZRLMPI.cpp: In function ‘void recv_internal(int*, int, uint8_t, int, int, uint8_t, uint8_t*)’:\n",
      "LIB//ZRLMPI.cpp:757:10: warning: comparison of integer expressions of different signedness: ‘int’ and ‘long unsigned int’ [-Wsign-compare]\n",
      "   if(ret > count*typewidth*sizeof(uint32_t))\n",
      "      ~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "LIB//ZRLMPI.cpp: In function ‘void ZRLMPI_print_stats()’:\n",
      "LIB//ZRLMPI.cpp:1067:10: warning: format ‘%lld’ expects argument of type ‘long long int’, but argument 2 has type ‘uint64_t’ {aka ‘long unsigned int’} [-Wformat=]\n",
      "   printf(\"\\ttotal number of recvfrom calls: %lld\\n\", total_recv_call_numbers);\n",
      "          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~  ~~~~~~~~~~~~~~~~~~~~~~~\n",
      "LIB//ZRLMPI.cpp: In function ‘int main(int, char**)’:\n",
      "LIB//ZRLMPI.cpp:1095:34: warning: ISO C++ forbids variable length array ‘argv_mpi_app’ [-Wvla]\n",
      "   char *argv_mpi_app[argc_mpi_app];\n",
      "                                  ^\n",
      "LIB//zrlmpi_common.cpp:25: warning: ignoring #pragma HLS INLINE [-Wunknown-pragmas]\n",
      " #pragma HLS INLINE\n",
      " \n",
      "LIB//zrlmpi_common.cpp:37: warning: ignoring #pragma HLS INLINE [-Wunknown-pragmas]\n",
      " #pragma HLS INLINE\n",
      " \n",
      "LIB//zrlmpi_common.cpp:49: warning: ignoring #pragma HLS inline [-Wunknown-pragmas]\n",
      " #pragma HLS inline\n",
      " \n",
      "LIB//zrlmpi_common.cpp:72: warning: ignoring #pragma HLS INLINE [-Wunknown-pragmas]\n",
      " #pragma HLS INLINE\n",
      " \n",
      "LIB//zrlmpi_common.cpp:108: warning: ignoring #pragma HLS INLINE [-Wunknown-pragmas]\n",
      " #pragma HLS INLINE\n",
      " \n",
      "LIB//zrlmpi_common.cpp:119: warning: ignoring #pragma HLS INLINE [-Wunknown-pragmas]\n",
      " #pragma HLS INLINE\n",
      " \n",
      "LIB//zrlmpi_common.cpp:120: warning: ignoring #pragma HLS latency [-Wunknown-pragmas]\n",
      " #pragma HLS latency max=1\n",
      " \n",
      "LIB//zrlmpi_common.cpp:198: warning: ignoring #pragma HLS INLINE [-Wunknown-pragmas]\n",
      " #pragma HLS INLINE\n",
      " \n",
      "LIB//zrlmpi_common.cpp:199: warning: ignoring #pragma HLS latency [-Wunknown-pragmas]\n",
      " #pragma HLS latency max=1\n",
      " \n",
      "cp: cannot stat '/cloudFPGA/current_dcps/3_*': No such file or directory\n",
      "ln: failed to create symbolic link 'cFDK/cFDK': File exists\n",
      "ln: failed to create symbolic link 'env/cfenv-small/cfenv-small': File exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DOSA:hls4mlOSG:INFO] Small input, using reuse_factor 1.\n",
      "[DOSA:hls4mlOSG:INFO] starting hls4ml tool...\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[1, 17]], output shape: [1, 17]\n",
      "Layer name: fn_0001_nn_dense, layer type: Dense, input shapes: [[1, 17]], output shape: [1, 16]\n",
      "Layer name: fn_0002_nn_dense, layer type: Dense, input shapes: [[1, 16]], output shape: [1, 8]\n",
      "Layer name: fn_0003_nn_dense, layer type: Dense, input shapes: [[1, 8]], output shape: [1, 4]\n",
      "Creating HLS model\n",
      "Writing HLS project\n",
      "Done\n",
      "[DOSA:hls4mlOSG:DEBUG] determined prod_with: 17\n",
      "[DOSA:hls4mlOSG:DEBUG] determined prod_with: 17\n",
      "\n",
      "[VERBOSE] best draft found:\n",
      "{\n",
      "  \"name\": \"EVEREST traffic prediction v1\",\n",
      "  \"total_flops\": 836.0,\n",
      "  \"total_parameter_bytes\": 6552,\n",
      "  \"predicted_performance_iter_hz\": 310882.260827914,\n",
      "  \"total_dse_time_s\": \"0.02\",\n",
      "  \"total_nodes\": 0,\n",
      "  \"nodes\": [\n",
      "    {\n",
      "      \"folder\": \"node_0\",\n",
      "      \"ranks\": [\n",
      "        0\n",
      "      ],\n",
      "      \"type\": \"CPU_dummy_x86-1\",\n",
      "      \"blocks\": [],\n",
      "      \"bricks\": {\n",
      "        \"0\": {\n",
      "          \"name\": \"(output)\",\n",
      "          \"brick_uuid\": 0,\n",
      "          \"op_calls\": []\n",
      "        },\n",
      "        \"1\": {\n",
      "          \"name\": \"(input)\",\n",
      "          \"brick_uuid\": 1,\n",
      "          \"op_calls\": []\n",
      "        }\n",
      "      },\n",
      "      \"estimations\": {\n",
      "        \"comp_util%\": 0,\n",
      "        \"mem_util%\": 0,\n",
      "        \"req_iter_hz\": 1.0,\n",
      "        \"used_iter_hz\": -1.0,\n",
      "        \"theoretical_max_iter\": -1.0,\n",
      "        \"impl_Gflop_eqiv\": -1e-09,\n",
      "        \"max_Gflop_based_on_impl_eqiv\": -1e-09\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"folder\": \"node_1\",\n",
      "      \"ranks\": [\n",
      "        1\n",
      "      ],\n",
      "      \"type\": \"cF_FMKU60_Themisto-Role_1\",\n",
      "      \"blocks\": [\n",
      "        \"ArchBlock(id: 0, OSG(hls4ml OSG, for [<DosaHwClasses.FPGA_xilinx: 4>]), BrickImplTypes.STREAM, [0, 1, 2])\"\n",
      "      ],\n",
      "      \"bricks\": {\n",
      "        \"2\": {\n",
      "          \"name\": \"fn_0001\",\n",
      "          \"brick_uuid\": 2,\n",
      "          \"op_calls\": [\n",
      "            \"nn.dense\",\n",
      "            \"nn.multi_threshold\"\n",
      "          ]\n",
      "        },\n",
      "        \"3\": {\n",
      "          \"name\": \"fn_0002\",\n",
      "          \"brick_uuid\": 3,\n",
      "          \"op_calls\": [\n",
      "            \"nn.dense\",\n",
      "            \"nn.multi_threshold\"\n",
      "          ]\n",
      "        },\n",
      "        \"4\": {\n",
      "          \"name\": \"fn_0003\",\n",
      "          \"brick_uuid\": 4,\n",
      "          \"op_calls\": [\n",
      "            \"nn.dense\"\n",
      "          ]\n",
      "        }\n",
      "      },\n",
      "      \"estimations\": {\n",
      "        \"comp_util%\": 3.195833704806804,\n",
      "        \"mem_util%\": 1.6169797773803218,\n",
      "        \"req_iter_hz\": 1.0,\n",
      "        \"used_iter_hz\": 310882.260827914,\n",
      "        \"theoretical_max_iter\": 9727735.844337609,\n",
      "        \"impl_Gflop_eqiv\": 0.28570079770085294,\n",
      "        \"max_Gflop_based_on_impl_eqiv\": 8.93978924094626\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "[DEBUG] profiling information: \n",
      "{\n",
      "  \"archGen_time_total_s\": 0.5057821273803711,\n",
      "  \"tvm_pass_time_s\": 0.011359930038452148,\n",
      "  \"creating_draft_time_s\": 0.0013422966003417969,\n",
      "  \"optimizing_draft_time_s\": 0.0058443546295166016,\n",
      "  \"creating_annotations_time_s\": 1.9550323486328125e-05,\n",
      "  \"check_annotations_time_1_s\": 2.8133392333984375e-05,\n",
      "  \"find_best_draft_time_s\": 0.0030541419982910156,\n",
      "  \"dse_time\": 0.02469778060913086,\n",
      "  \"build_total_time_s\": 0.4809384346008301\n",
      "}\n",
      "\t...done.\n",
      "\n",
      "\n",
      "DOSA finished successfully.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# to enable the roofline graphics\n",
    "# emli.enable_roofline_gui()\n",
    "\n",
    "emli.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ae91b26-770a-4cd6-ad5a-e2e2274155ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 56\n",
      "-rw-rw-r--. 1 ngl ngl  2568 Jan 30 10:53 arch_info.json\n",
      "drwxrwxr-x. 5 ngl ngl    56 Jan 30 10:08 cFBuild1\n",
      "-rw-rw-r--. 1 ngl ngl   394 Jan 30 10:53 cluster.json\n",
      "-rwxrwxr-x. 1 ngl ngl   752 Jan 30 10:53 dosa_build.sh\n",
      "-rw-rw-r--. 1 ngl ngl  9343 Jan 30 10:53 dosa_deploy.py\n",
      "-rw-rw-r--. 1 ngl ngl  2383 Jan 30 10:53 dosa_report.py\n",
      "-rw-rw-r--. 1 ngl ngl 20565 Jan 30 10:53 generated_architecture.json\n",
      "-rw-rw-r--. 1 ngl ngl   346 Jan 30 10:53 ml_inference.section\n",
      "drwxrwxr-x. 3 ngl ngl   167 Jan 30 10:53 node_0\n",
      "drwxrwxr-x. 6 ngl ngl   125 Jan 30 10:53 node_1\n",
      "drwxrwxr-x. 3 ngl ngl    75 Jan 30 10:53 quantized_model\n",
      "drwxrwxr-x. 2 ngl ngl     6 Jan 29 18:53 tmp_rpt_dir\n"
     ]
    }
   ],
   "source": [
    "! ls -l build_dirs/etp_v1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274247da-29e2-4668-8d64-2bed4b050214",
   "metadata": {},
   "source": [
    "Please pay attention to the `ml_inference.section` file, which we will need later to introduce this \"application variant\". "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ffb10b-71af-41eb-9de2-100f2a3bf196",
   "metadata": {},
   "source": [
    "Basecamp Climbs part & App emit\n",
    "------------------------------------\n",
    "This part assumes the software-only app exists with the necessary annotations, as shown in the example below: \n",
    "For `app.py` this is:\n",
    "```\n",
    "...\n",
    "# to indicate the initialization (yes, the @basecamp 'pragma' is a comment)\n",
    "# @basecamp climbs init args={\"action_name\" : \"sys.argv[4]\", \"host_address\" : \"sys.argv[5]\"}\n",
    "...\n",
    "\n",
    "# then, to mark the code to accelerate\n",
    "...\n",
    "x = torch.from_numpy(din).float()\n",
    "# @basecamp climbs accelerate begin args={\"x\": \"x\", \"y\": \"y_pred\"}\n",
    "dnn.update_coeffs(coeffs, road_id)\n",
    "y = dnn(x)\n",
    "y_pred = y.detach().numpy()\n",
    "# @basecamp climbs accelerate end\n",
    "...\n",
    "\n",
    "```\n",
    "\n",
    "Also, the `Dockerfile` has the following comment (after installing python, but before `ENTRYPOINT`):\n",
    "```\n",
    "# @basecamp climbs init\n",
    "```\n",
    "\n",
    "The necessary arguments to list in the `args=` JSON annotation is explained using the `ebc climbs describe --flow` command (or the python API)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8f1cdc5-66ca-470b-99ef-2a558fc47707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ML inference flow of the EVEREST SDK requires the following arguments:\n",
      "1. Setup:\n",
      "    - The `action_name` of the corresponding IBM cloudFPGA service.\n",
      "    - The `host_address` (host ip address) to be used to connect to the FPGAs.\n",
      "    - Both are then submitted via `dosa_net.init_from_action(action_name, host_address)`\n",
      "2. Execution:\n",
      "    - One numpy.ndarray `x` as input, where the first axis are the batches. \n",
      "    - The output is returned in another array `y`.\n",
      "    - The inference is then called via `y = dosa_net.infer_batch(x)`\n"
     ]
    }
   ],
   "source": [
    "basecamp.climbs.describe('ml_inference')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5f8274-9c73-4429-82b4-5107746ab53a",
   "metadata": {},
   "source": [
    "### Combine the Climb\n",
    "Now, we add all the necessary files of the SW only --- i.e. the \"main\" app --- to everest basecamp climbs (or `e_climbs`). Then, we add the accelerated version combiled by DOSA as module/variant. Finally, we emit the combined app. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77e14cb1-289d-4db4-b24f-55c447dc1406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Climb /home/ngl/gitrepos/EVEREST/traffic_prediction/build_dirs/tpred_integrated_v1/accelerated_tpred_simple.climb created successfully.\n"
     ]
    }
   ],
   "source": [
    "e_climbs = basecamp.climbs\n",
    "# first, create a new Climb\n",
    "e_climbs.create('accelerated_tpred_simple', '/home/ngl/gitrepos/EVEREST/traffic_prediction/build_dirs/tpred_integrated_v1/')\n",
    "# please note the resulting `.climb` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "440bf8c7-a14a-4e47-b24a-2ce9c8c06ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 24\n",
      "-rw-rw-r--. 1 ngl ngl 7010 Jan 29 20:06 app.py\n",
      "-rw-rw-r--. 1 ngl ngl  790 Jan 29 18:14 client.py\n",
      "drwxrwxr-x. 2 ngl ngl   64 Jan 29 19:56 data\n",
      "-rw-rw-r--. 1 ngl ngl  285 Jan 29 19:27 Dockerfile\n",
      "-rw-rw-r--. 1 ngl ngl  704 Jan 29 18:42 Readme.md\n",
      "-rw-rw-r--. 1 ngl ngl  180 Jan 29 18:14 requirements.txt\n"
     ]
    }
   ],
   "source": [
    "! ls -l traffic_prediction/tpred_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19b61045-b4d6-48b9-9717-6b137b12ae8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_climb_file = 'build_dirs/tpred_integrated_v1/accelerated_tpred_simple.climb'\n",
    "app_dir = 'traffic_prediction/tpred_app/'\n",
    "\n",
    "# now, we add all the files of the SW only app\n",
    "e_climbs.add_file(app_dir + 'app.py', 'python', my_climb_file)\n",
    "e_climbs.add_file(app_dir + 'Dockerfile', 'docker', my_climb_file)\n",
    "# 'copy' means, the files are copied without modification/analysis, also directorys are copied recursively\n",
    "e_climbs.add_file(app_dir + 'client.py', 'copy', my_climb_file)\n",
    "e_climbs.add_file(app_dir + 'data/', 'copy', my_climb_file)\n",
    "e_climbs.add_file(app_dir + 'Readme.md', 'copy', my_climb_file)\n",
    "e_climbs.add_file(app_dir + 'requirements.txt', 'copy', my_climb_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac78b23c-4c85-47d3-b2af-5b2c5954baae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, we add the DOSA compiled files as 'variant'\n",
    "e_climbs.add_module('traffic_prediction/build_dirs/etp_v1/ml_inference.section', my_climb_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5a58a3-5924-4cd4-912f-175402a166f3",
   "metadata": {},
   "source": [
    "### Emit the Climb\n",
    "i.e. generate the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f65280d6-b85a-479a-bfb9-79f724fd6cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING   MainThread      Climbs         : emit            2024-01-30 10:53:40,285: Using the output directory: /home/ngl/gitrepos/EVEREST/traffic_prediction/build_dirs/tpred_integrated_v1\n"
     ]
    }
   ],
   "source": [
    "e_climbs.emit(my_climb_file)\n",
    "# optionaly, an output directory could be specified. \n",
    "# If not, the directory where the `.climb` file is will be used: 'traffic_prediction/build_dirs/tpred_integrated_v1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29ce5055-b144-4b81-b395-d3cdfef8f487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 60\n",
      "-rw-rw-r--. 1 ngl ngl   745 Jan 30 10:53 accelerated_tpred_simple.climb\n",
      "-rw-rw-r--. 1 ngl ngl 11502 Jan 30 10:53 app.py\n",
      "-rw-rw-r--. 1 ngl ngl  1234 Jan 30 10:53 basecamp_build_and_run_instructions.md\n",
      "-rw-rw-r--. 1 ngl ngl   790 Jan 30 10:53 client.py\n",
      "-rw-rw-r--. 1 ngl ngl   394 Jan 30 10:53 cluster.json\n",
      "drwxrwxr-x. 2 ngl ngl    64 Jan 30 10:33 data\n",
      "-rw-rw-r--. 1 ngl ngl   485 Jan 30 10:53 Dockerfile\n",
      "-rw-rw-r--. 1 ngl ngl  9343 Jan 30 10:53 dosa_deploy.py\n",
      "-rw-rw-r--. 1 ngl ngl  1723 Jan 30 10:53 margot.json\n",
      "drwxrwxr-x. 4 ngl ngl   181 Jan 30 10:37 node_0\n",
      "-rw-rw-r--. 1 ngl ngl   420 Jan 30 10:53 ops.json\n",
      "-rw-rw-r--. 1 ngl ngl   704 Jan 30 10:53 Readme.md\n",
      "-rw-rw-r--. 1 ngl ngl   180 Jan 30 10:53 requirements.txt\n"
     ]
    }
   ],
   "source": [
    "! ls -l traffic_prediction/build_dirs/tpred_integrated_v1/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7db6158-5ba8-4f16-804a-e19d3d7bdc92",
   "metadata": {},
   "source": [
    "Now, the app is emitted and the code can switch dynamically between the SW only or the FPGA version, depending on the availability of the FPGAs. \n",
    "\n",
    "For example, the `app.py` has the following code inserted:\n",
    "```python\n",
    "# at the place where the # @basecamp climbs init was:\n",
    "# generated by EVEREST basecamp\n",
    "from node_0 import dosa_root\n",
    "dosa_net = dosa_root.DosaRoot(8)\n",
    "dosa_net.init_from_action(sys.argv[4], sys.argv[5])\n",
    "dosa_net.reset()\n",
    "\n",
    "# at the place where the # @basecamp climbs accelerate was:\n",
    "# generated by EVEREST basecamp\n",
    "import time\n",
    "\n",
    "@tune(tuner,\n",
    "      knobs=[{\"name\": \"version\", \"type\": \"int\"}],\n",
    "      metrics=[{\"name\": \"time\", \"function\": extract_time}],\n",
    "      features=[{\"name\": \"hw\", \"function\": margot_select_variant}])\n",
    "def everest_accelerate(version = 0):\n",
    "    start = time.time()\n",
    "    try:\n",
    "        if variant == 0:\n",
    "            dnn.update_coeffs(coeffs, road_id)\n",
    "            y = dnn(x)\n",
    "            y_pred = y.detach().numpy()\n",
    "        if variant == 1:\n",
    "            y_pred = dosa_net.infer_batch(x)\n",
    "        except:  # fallback to cpu version\n",
    "            dnn.update_coeffs(coeffs, road_id)\n",
    "            y = dnn(x)\n",
    "            y_pred = y.detach().numpy()\n",
    "    end = time.time()\n",
    "    return end-start\n",
    "\n",
    "everest_accelerate()\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4be376-7d06-4005-95b6-8e72e8d50507",
   "metadata": {},
   "source": [
    "Further build and run instructions can be found in `tpred_integrated_v1/basecamp_build_and_run_instructions.md`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ad8afce-67e4-46d9-a1e5-b4fd58fe3d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build and run instructions for the EVEREST accelerated app: accelerated_tpred_simple\n",
      "=====================================================================================\n",
      "\n",
      "\n",
      "Build:\n",
      "-------\n",
      "\n",
      "For the runtime tuner:\n",
      "```bash\n",
      "sudo snap install mosquitto  # or other ways: https://mosquitto.org/download/\n",
      "docker pull margotpolimi/brian:1.0\n",
      "docker pull margotpolimi/stub_agora:1.0\n",
      "```\n",
      "\n",
      "Apparently, the app has it's own Dockerfile, so maybe:\n",
      "```bash\n",
      "docker build -f Dockerfile -t ebc_accelerated_accelerated_tpred_simple:latest .\n",
      "```\n",
      "\n",
      "Furthermore, the following modules have specific installation instructions:\n",
      "- **`ml_inference`**:\n",
      "Some python modules are required (will be executed by the Dockerfile, if applicable):\n",
      "```\n",
      "virtualenv venv -p /usr/bin/python3.8\n",
      ". venv/bin/activate\n",
      "pip install -r node_0/requirements.txt\n",
      "```\n",
      "\n",
      "\n",
      "Run:\n",
      "-------\n",
      "\n",
      "For the runtime tuner:\n",
      "```bash\n",
      "docker run -d --rm --network host --name brian margotpolimi/brian:1.0\n",
      "docker run -d --rm --network host --name stub_agora margotpolimi/stub_agora:1.0\n",
      "mosquitto_pub -t agora/traffic^0.1^block1/knowledge -f ops.json\n",
      "```\n",
      "\n",
      "To start the app container, maybe:\n",
      "```bash\n",
      "docker run --rm --network host -it --name ebc_accelerated_accelerated_tpred_simple\n",
      "```\n",
      "\n",
      "Happy EVEREST climbing!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! cat traffic_prediction/build_dirs/tpred_integrated_v1/basecamp_build_and_run_instructions.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3624da13-b4e6-4642-82a5-80f4c2c6ab98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EVEREST basecamp (venv)",
   "language": "python",
   "name": "venv-ebc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

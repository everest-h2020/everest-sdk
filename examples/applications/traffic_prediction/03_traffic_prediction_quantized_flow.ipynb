{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5029cb88-edc0-4bc0-8eb7-3c3eedce3c86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# after kernel restart, always execute this line\n",
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.insert(0, 'path/to/everest-basecamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c55db03-537c-4422-b258-0ec8ceacf4db",
   "metadata": {},
   "source": [
    "ML-developer part\n",
    "---------------------------\n",
    "Below is the a pytorch code to develop a small DNN inference application using already trained coefficients. Also, we use parts of the training data set to better calibrate the weights for the quantized domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76842e10-ef50-4d6e-b1a7-5bfba8b198ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_prefix = './tpred_v7_20230417/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa281019-0e1e-4303-9ad6-ef9f5ff754a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ngl/gitrepos/EVEREST/everest-basecamp/venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class TPNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dense1 = nn.Linear(17, 16)\n",
    "        self.dense2 = nn.Linear(16, 8)\n",
    "        self.dense3 = nn.Linear(8, 4)\n",
    "\n",
    "        self.L1 = self.dense1\n",
    "        self.L2 = self.dense2\n",
    "        self.L3 = self.dense3\n",
    "        self.all_weights = [self.dense1.weight, self.dense1.bias, self.dense2.weight, self.dense2.bias,\n",
    "                            self.dense3.weight, self.dense3.bias]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.dense1(x))\n",
    "        x = self.relu(self.dense2(x))\n",
    "        x = self.dense3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def _tf_to_torch_param(x: np.ndarray):\n",
    "    ret = nn.parameter.Parameter(torch.tensor(x.T).type(torch.FloatTensor))\n",
    "    return ret\n",
    "\n",
    "\n",
    "def load_from_pkl_files(dnn: nn.Module, used_rid=0):\n",
    "    # from tf2_174_infer_sequential_M10_2.py\n",
    "    import pickle\n",
    "    import glob\n",
    "    import re\n",
    "\n",
    "    NI = 17  # kernel vector input size\n",
    "    L1 = 16  # layer 1 internal size\n",
    "    L2 = 8  # layer 2 internal size\n",
    "    NO = 4  # kernel vector output size\n",
    "    M = 10  # number of models\n",
    "\n",
    "    # NN coefficients data read-only storage\n",
    "    W1 = np.zeros((M, NI, L1))\n",
    "    B1 = np.zeros((M, L1))\n",
    "    W2 = np.zeros((M, L1, L2))\n",
    "    B2 = np.zeros((M, L2))\n",
    "    W3 = np.zeros((M, L2, NO))\n",
    "    B3 = np.zeros((M, NO))\n",
    "\n",
    "    # reading all coefficient files _coeffs_xxx.pkl (pickle)\n",
    "    cflist = [f for f in glob.glob(path_prefix+\"*.pkl\")]\n",
    "    for filename in cflist:\n",
    "        match = re.search('_coeffs_(.+?).pkl', filename)\n",
    "        rid = 0\n",
    "        if match:\n",
    "            rid = int(match.group(1))\n",
    "        if rid < 0 or rid >= M:\n",
    "            continue  # ignore models oo range\n",
    "        # print(\"reading dataset\", rid)\n",
    "\n",
    "        with open(filename, 'rb') as f:\n",
    "            coeffs = pickle.load(f)\n",
    "            W1[rid] = np.array(coeffs[0])\n",
    "            B1[rid] = np.array(coeffs[1])\n",
    "            W2[rid] = np.array(coeffs[2])\n",
    "            B2[rid] = np.array(coeffs[3])\n",
    "            W3[rid] = np.array(coeffs[4])\n",
    "            B3[rid] = np.array(coeffs[5])\n",
    "\n",
    "    dnn.L1.weight = _tf_to_torch_param(W1[used_rid])\n",
    "    dnn.L1.bias = _tf_to_torch_param(B1[used_rid])\n",
    "    dnn.L2.weight = _tf_to_torch_param(W2[used_rid])\n",
    "    dnn.L2.bias = _tf_to_torch_param(B2[used_rid])\n",
    "    dnn.L3.weight = _tf_to_torch_param(W3[used_rid])\n",
    "    dnn.L3.bias = _tf_to_torch_param(B3[used_rid])\n",
    "\n",
    "    return dnn\n",
    "\n",
    "\n",
    "def read_example_vectors():\n",
    "    N = 1000\n",
    "    M = 10  # number of models\n",
    "    # data vector inputs\n",
    "    import pandas as pd\n",
    "    d = pd.read_csv(path_prefix + \"_traffic_dataset_20230426.csv\")\n",
    "    d = d.to_numpy()\n",
    "    # sel = d[0:N, 0]\n",
    "    # sel = sel.astype(int)\n",
    "    # sel = np.array([x % M for x in sel])  # temporary hack\n",
    "    x = d[0:N, 1:18]\n",
    "    return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7292a0ec-d668-47f7-9af6-e785063ea24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing DNN to ./etp_01.pt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "torch_store_path = './etp_01.pt'\n",
    "dnn = TPNN()\n",
    "load_from_pkl_files(dnn)\n",
    "\n",
    "print(f'Storing DNN to {torch_store_path}')\n",
    "# export weights as state dict\n",
    "torch.save(dnn.state_dict(), f\"{torch_store_path}_state_dict\")\n",
    "# export complete model as torch script\n",
    "model_scripted = torch.jit.script(dnn)\n",
    "model_scripted.save(torch_store_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "463b4e9d-ab37-4f61-bae4-ef29e7ce427d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = read_example_vectors()\n",
    "numpy_store_path = './traffic_data_2023-04-26.npy'\n",
    "np.save(numpy_store_path, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ae5122-4ff1-46af-a905-aade88d743f3",
   "metadata": {},
   "source": [
    "The next cell is just there to show also the pytorch model works..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2132623-edb1-43b1-bcaa-d2a696395b1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference 0\n",
      "(0, array([30.545656, 40.80023 , 34.346386, 42.262363], dtype=float32))\n",
      "(0, array([25.729465, 24.704857, 16.780256, 26.248438], dtype=float32))\n",
      "(0, array([35.45301 , 34.960674, 34.22544 , 43.827374], dtype=float32))\n",
      "(0, array([4.0733585, 2.9853544, 2.1709018, 2.6423662], dtype=float32))\n",
      "(0, array([37.432034, 47.356346, 43.17812 , 49.02317 ], dtype=float32))\n",
      "(0, array([28.012989, 24.696459, 21.040972, 27.595472], dtype=float32))\n",
      "(0, array([41.50566, 41.57171, 34.12154, 52.50362], dtype=float32))\n",
      "(0, array([15.028785 , 16.173925 , 14.4315815, 16.47795  ], dtype=float32))\n",
      "(0, array([37.151417, 43.334423, 38.131054, 52.717567], dtype=float32))\n",
      "(0, array([25.99692 , 27.607416, 21.113655, 28.623783], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "used_road_id = 0\n",
    "M = 10  # still ocrrect?\n",
    "N = 1000\n",
    "\n",
    "Y_out = []\n",
    "with torch.no_grad():\n",
    "    for index in range(N):\n",
    "        if index % 1000 == 0:\n",
    "            print(\"inference\", index)\n",
    "        road_id = used_road_id\n",
    "        vin = torch.tensor(x[index]).type(torch.FloatTensor)\n",
    "        y_pred = dnn(vin)\n",
    "        y_numpy = y_pred.numpy()\n",
    "        Y_out.append((road_id, y_numpy))\n",
    "\n",
    "for item in Y_out[0:10]:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ad8b462-ac4f-423e-9b8c-38105fafebef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r--. 1 ngl ngl   13553 Jan 29 18:50 etp_01.pt\n",
      "-rw-rw-r--. 1 ngl ngl    4111 Jan 29 18:50 etp_01.pt_state_dict\n"
     ]
    }
   ],
   "source": [
    "! ls -l | grep *.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ebbf45-40a2-4233-b69c-9ef76e7285e5",
   "metadata": {},
   "source": [
    "Now, we start using **Everest basecamp**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "217be805-3544-4640-a4ed-ae35ba64ee20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ebc import basecamp\n",
    "\n",
    "\n",
    "# batch_size = 10000\n",
    "batch_size = 1\n",
    "precision = 8\n",
    "\n",
    "emli = basecamp.ml_inference\n",
    "emli.set_constraints(app_name=\"EVEREST traffic prediction v1\",\n",
    "                     onnx_input_name='x',\n",
    "                     input_shape=[batch_size, 17],\n",
    "                     input_size_t=precision,\n",
    "                     quantization='int8',  # that's new\n",
    "                     batch_size=batch_size,\n",
    "                     target_throughput=1,  # batch_size inferences per second\n",
    "                     arch_gen_strategy='throughput'\n",
    "                     )\n",
    "emli.set_output_path('traffic_prediction/build_dirs/etp_v1')\n",
    "\n",
    "emli.set_model_path(\"torchscript\", './etp_01.pt')\n",
    "\n",
    "emli.set_calibration_data_path('./traffic_data_2023-04-26.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79225f59-6166-4975-9b83-0f76ceced923",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emli.disable_build = True  # or define environemnt_path DOSA_cFBuild1_used_dcps_path\n",
    "emli.compile()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EVEREST basecamp (venv)",
   "language": "python",
   "name": "venv-ebc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
